# Performance Test Prompt Template

æ€§èƒ½æµ‹è¯•çš„ prompt æ¨¡æ¿ã€‚

## åœºæ™¯

- API æ€§èƒ½æµ‹è¯•
- è´Ÿè½½æµ‹è¯•
- å‹åŠ›æµ‹è¯•
- Spike æµ‹è¯•
- æŒä¹…æµ‹è¯•

## Prompt æ¨¡æ¿

```
ä¸ºä»¥ä¸‹ API ç¼–å†™æ€§èƒ½æµ‹è¯•è„šæœ¬ï¼š

## API å®šä¹‰
- **æ–¹æ³•ï¼š** [GET/POST/PUT/DELETE]
- **è·¯å¾„ï¼š** /api/[endpoint]
- **è¯·æ±‚å¤´ï¼š** [è®¤è¯å¤´ç­‰]

## æ€§èƒ½ç›®æ ‡
- **å“åº”æ—¶é—´ (p50)ï¼š** < X ms
- **å“åº”æ—¶é—´ (p95)ï¼š** < Y ms
- **å“åº”æ—¶é—´ (p99)ï¼š** < Z ms
- **ååé‡ï¼š** > X req/s
- **é”™è¯¯ç‡ï¼š** < Y %

## æµ‹è¯•åœºæ™¯
1. **åŸºå‡†æµ‹è¯•** - 10 å¹¶å‘ç”¨æˆ·
2. **æ­£å¸¸è´Ÿè½½** - 100 å¹¶å‘ç”¨æˆ·
3. **å‹åŠ›æµ‹è¯•** - 1000 å¹¶å‘ç”¨æˆ·
4. **çªå‘æµ‹è¯•** - çªç„¶å¢åŠ åˆ° 2000 ç”¨æˆ·
5. **æŒä¹…æµ‹è¯•** - æŒç»­è´Ÿè½½ 30 åˆ†é’Ÿ

## æµ‹è¯•å·¥å…·
[k6/JMeter/Locust/Gatling]

## è¦æ±‚
1. æä¾›å®Œæ•´çš„æµ‹è¯•è„šæœ¬
2. åŒ…å«ç»“æœåˆ†æé€»è¾‘
3. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
4. ä¸ç›®æ ‡å€¼è¿›è¡Œæ¯”è¾ƒ

## è¾“å‡º
æä¾›æµ‹è¯•è„šæœ¬å’Œä½¿ç”¨è¯´æ˜ã€‚
```

## å®é™…ä¾‹å­

### ä¾‹å­ï¼šAPI æ€§èƒ½æµ‹è¯•

```
Write performance test scripts for the products API.

## API Definition
- **Method:** GET
- **Path:** /api/products
- **Headers:** Authorization: Bearer [token]

## Request Parameters
- `page`: Page number (default: 1)
- `limit`: Items per page (default: 20)
- `category`: Filter by category (optional)

## Performance Targets
- **Response Time (p95):** < 200ms
- **Response Time (p99):** < 500ms
- **Throughput:** > 1000 req/s
- **Error Rate:** < 0.1%

## Test Scenarios
1. **Baseline test** - 10 concurrent users for 1 minute
2. **Normal load** - 100 concurrent users for 2 minutes
3. **Stress test** - 1000 concurrent users for 5 minutes
4. **Sustained test** - 500 concurrent users for 30 minutes

## Test Tool
k6

## Requirements
1. Provide complete test script
2. Include custom metrics (response time, error rate, throughput)
3. Generate HTML performance report
4. Compare against targets in summary

## Output
Provide test script and usage instructions.
```

**ç¤ºä¾‹è¾“å‡ºï¼ˆk6ï¼‰ï¼š**

```javascript
// performance/products-api.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate, Trend, Counter } from 'k6/metrics';

// Custom metrics
const errorRate = new Rate('errors');
const responseTime = new Trend('response_time');
const requestCount = new Counter('requests');

// Test configuration
export const options = {
  stages: [
    // Stage 1: Ramp up to baseline
    { duration: '30s', target: 10 },

    // Stage 2: Stay at baseline
    { duration: '1m', target: 10 },

    // Stage 3: Ramp up to normal load
    { duration: '1m', target: 100 },

    // Stage 4: Stay at normal load
    { duration: '2m', target: 100 },

    // Stage 5: Ramp up to stress
    { duration: '2m', target: 1000 },

    // Stage 6: Stay at stress
    { duration: '5m', target: 1000 },

    // Stage 7: Spike test
    { duration: '1m', target: 2000 },

    // Stage 8: Ramp down
    { duration: '2m', target: 0 },
  ],

  // Thresholds - fail test if these aren't met
  thresholds: {
    http_req_duration: ['p(95)<200', 'p(99)<500'], // Response time
    errors: ['rate<0.01'],                           // Error rate < 1%
    http_req_failed: ['rate<0.01'],                  // Failed requests < 1%
  },
};

// Default headers
const headers = {
  'Authorization': 'Bearer valid_test_token',
  'Content-Type': 'application/json',
};

export default function () {
  // Make API request with pagination
  const page = Math.floor(Math.random() * 50) + 1; // Random page 1-50
  const url = `https://api.example.com/products?page=${page}&limit=20`;

  const response = http.get(url, { headers });

  // Record metrics
  const isSuccess = check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
    'has products array': (r) => {
      const body = JSON.parse(r.body);
      return Array.isArray(body.products);
    },
    'products count <= 20': (r) => {
      const body = JSON.parse(r.body);
      return body.products.length <= 20;
    },
  });

  // Update custom metrics
  errorRate.add(!isSuccess);
  responseTime.add(response.timings.duration);
  requestCount.add(1);

  // Sleep between requests (simulate real user behavior)
  sleep(Math.random() * 2 + 1); // 1-3 seconds
}

// Handle summary - generate report
export function handleSummary(data) {
  return {
    'performance-report.json': JSON.stringify(data),
    'stdout': JSON.stringify({
      'metrics': {
        'http_req_duration': {
          'avg': data.metrics.http_req_duration.values.avg,
          'p95': data.metrics.http_req_duration.values['p(95)'],
          'p99': data.metrics.http_req_duration.values['p(99)'],
        },
        'http_reqs': data.metrics.http_reqs.values.count,
        'vus': data.metrics.vus.values.max,
      },
      'checks': {
        pass_rate: data.metrics.checks.values.passes /
                   (data.metrics.checks.values.passes + data.metrics.checks.values.fails),
      },
    }, null, 2),
  };
}
```

### ä½¿ç”¨è¯´æ˜

```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
k6 run performance/products-api.js

# ç”Ÿæˆ HTML æŠ¥å‘Š
k6 run --out json=results.json performance/products-api.js
k6-reporter results.json

# è¿è¡ŒæŒ‡å®šé˜¶æ®µ
k6 run --stage '{"duration":"1m","target":100}' performance/products-api.js
```

## Locust ç¤ºä¾‹

```python
# locustfile.py
from locust import HttpUser, task, between
import random

class ProductAPIUser(HttpUser):
    wait_time = between(1, 3)  # Wait 1-3 seconds between requests

    def on_start(self):
        """Called when a user starts."""
        # Login to get token
        response = self.client.post("/api/auth/login", json={
            "email": "test@example.com",
            "password": "password123"
        })
        self.token = response.json()["token"]

    @task(3)  # This task runs 3x more than others
    def get_products(self):
        """Get products list."""
        page = random.randint(1, 50)
        self.client.get(
            f"/api/products?page={page}&limit=20",
            headers={"Authorization": f"Bearer {self.token}"}
        )

    @task(1)
    def get_product_details(self):
        """Get single product details."""
        product_id = random.randint(1, 1000)
        self.client.get(
            f"/api/products/{product_id}",
            headers={"Authorization": f"Bearer {self.token}"}
        )

    @task(1)
    def search_products(self):
        """Search products."""
        query = random.choice(["laptop", "phone", "monitor", "keyboard"])
        self.client.get(
            f"/api/products/search?q={query}",
            headers={"Authorization": f"Bearer {self.token}"}
        )
```

**è¿è¡Œ Locust:**

```bash
# Headless mode
locust -f locustfile.py --headless -u 1000 -r 100 -t 5m

# With UI
locust -f locustfile.py --host https://api.example.com
```

## JMeter ç¤ºä¾‹

JMeter ä½¿ç”¨ GUI é…ç½®ï¼Œè¿™é‡Œæä¾›å…³é”®é…ç½®è¯´æ˜ï¼š

```
Thread Group (Users)
â”œâ”€â”€ Number of Threads: 1000
â”œâ”€â”€ Ramp-Up Period: 300 seconds
â””â”€â”€ Loop Count: Forever

HTTP Request
â”œâ”€â”€ Server: api.example.com
â”œâ”€â”€ Path: /api/products
â”œâ”€â”€ Method: GET
â””â”€â”€ Header Manager
    â””â”€â”€ Authorization: Bearer ${token}

CSV Data Set Config (for pagination)
â”œâ”€â”€ Filename: pages.csv
â”œâ”€â”€ Variable Names: page
â””â”€â”€ Looping: True

Listeners
â”œâ”€â”€ View Results Tree (debug)
â”œâ”€â”€ Aggregate Report (summary)
â”œâ”€â”€ Summary Report
â””â”€â”€ Response Times Over Time (graph)
```

## æ€§èƒ½æµ‹è¯•ç±»å‹

### 1. è´Ÿè½½æµ‹è¯•ï¼ˆLoad Testingï¼‰

**ç›®æ ‡ï¼š** éªŒè¯ç³»ç»Ÿåœ¨é¢„æœŸè´Ÿè½½ä¸‹çš„æ€§èƒ½

```
Write a load test for [API].

## Load Profile
- Concurrent users: [number]
- Test duration: [time]
- Request rate: [requests per second]

## Expected Performance
- Average response time: < X ms
- 95th percentile: < Y ms
- Error rate: < Z%

## Output
Provide complete load test script.
```

### 2. å‹åŠ›æµ‹è¯•ï¼ˆStress Testingï¼‰

**ç›®æ ‡ï¼š** æ‰¾å‡ºç³»ç»Ÿå´©æºƒç‚¹

```
Write a stress test to find the breaking point of [API].

## Test Plan
Gradually increase load until:
- Response time degrades significantly
- Error rate spikes
- System crashes or becomes unresponsive

## Ramp Up Strategy
Start at [X users], increase by [Y users] every [Z seconds]

## Output
Provide stress test script and monitoring plan.
```

### 3. Spike æµ‹è¯•

**ç›®æ ‡ï¼š** æµ‹è¯•ç³»ç»Ÿåº”å¯¹çªå‘æµé‡çš„èƒ½åŠ›

```
Write a spike test for [API].

## Spike Profile
- Baseline: [X users]
- Spike: [Y users] (sudden increase)
- Duration: [Z seconds]
- Recovery: Back to [X users]

## Expected Behavior
- System should handle spike gracefully
- No data loss
- Quick recovery after spike

## Output
Provide spike test script.
```

### 4. æŒä¹…æµ‹è¯•ï¼ˆSoak Testingï¼‰

**ç›®æ ‡ï¼š** æµ‹è¯•ç³»ç»Ÿé•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§

```
Write a soak test for [API].

## Test Configuration
- Duration: [e.g., 8 hours, 24 hours]
- Load: [X users] (normal production load)
- Monitoring: Check for memory leaks, performance degradation

## Key Metrics to Track
- Memory usage over time
- Response time trend
- Error rate over time
- CPU usage

## Output
Provide soak test script and monitoring setup.
```

## æ€§èƒ½åˆ†æå’Œä¼˜åŒ–

### Prompt: æ€§èƒ½åˆ†æ

```
Analyze the following performance test results:

## Test Results
[ç²˜è´´æµ‹è¯•ç»“æœæ•°æ®]

## System Info
- CPU: [specifications]
- RAM: [amount]
- Network: [bandwidth]
- Database: [type, version]

## Requirements
1. Identify bottlenecks
2. Compare against targets
3. Suggest optimization strategies
4. Prioritize improvements

## Output Format
### Performance Analysis

#### Overall Results
- Average response time: X ms (Target: Y ms) - âœ…/âŒ
- P95 response time: X ms (Target: Y ms) - âœ…/âŒ
- Throughput: X req/s (Target: Y req/s) - âœ…/âŒ
- Error rate: X% (Target: Y%) - âœ…/âŒ

#### Bottlenecks
1. [Bottleneck 1]
   - Evidence: [data]
   - Impact: [severity]
   - Suggested fix: [solution]

#### Optimization Recommendations
1. [Recommendation 1]
   - Expected improvement: [estimate]
   - Effort: [low/medium/high]
   - Priority: [1-5]
```

## æ€§èƒ½ä¼˜åŒ– Prompt

```
Optimize [component/code] for performance.

## Current Performance
- Benchmark results: [data]
- Bottlenecks identified: [list]

## Target Performance
- Response time: < X ms
- Throughput: > Y req/s
- Memory usage: < Z MB

## Constraints
- Cannot change [X]
- Must maintain [Y]
- Limited to [Z] resources

## Requirements
1. Analyze the current implementation
2. Identify optimization opportunities
3. Implement improvements
4. Add benchmarks to verify
5. Maintain correctness with tests

## Output
Provide optimized code and performance comparison.
```

## å¸¸è§æ€§èƒ½é—®é¢˜

### 1. N+1 æŸ¥è¯¢é—®é¢˜

```
Optimize this code to eliminate N+1 queries:

[ç²˜è´´ä»£ç ]

The code is making a database query for each item in a loop.

## Requirements
1. Use joins or subqueries to fetch all data in fewer queries
2. Add benchmarks before and after
3. Ensure the result is the same
4. Update related tests if needed
```

### 2. ç¼ºå°‘ç´¢å¼•

```
Analyze and optimize this slow query:

[SQL æŸ¥è¯¢]

## Current Performance
- Execution time: X ms
- Rows returned: Y

## Requirements
1. Use EXPLAIN ANALYZE to identify bottlenecks
2. Suggest appropriate indexes
3. Provide optimized query
4. Show performance improvement
```

### 3. å†…å­˜æ³„æ¼

```
Debug memory leak in [component].

## Symptoms
- Memory usage grows over time
- Eventually crashes with OOM

## Requirements
1. Identify the source of memory leak
2. Fix the leak
3. Add memory monitoring
4. Verify with a soak test
```

## æ€§èƒ½æµ‹è¯•æ£€æŸ¥æ¸…å•

```
Performance Test Checklist:

Test Design:
â–¡ Test objectives clearly defined
â–¡ Realistic workload simulated
â–¡ Performance targets defined
â–¡ Test environment matches production (as much as possible)
â–¡ Test data is representative

Test Execution:
â–¡ Warm-up period included
â–¡ Tests run long enough to reach steady state
â–¡ Multiple runs for statistical significance
â–¡ System monitoring in place
â–¡ Results captured and stored

Analysis:
â–¡ Compare against baseline
â–¡ Identify bottlenecks
â–¡ Document findings
â–¡ Prioritize improvements
â–¡ Share results with team

Optimization:
â–¡ Top bottlenecks addressed first
â–¡ Before/after benchmarks
â–¡ Regression testing
â–¡ Production deployment plan
```

## å·¥å…·å¯¹æ¯”

| ç‰¹æ€§ | k6 | Locust | JMeter | Gatling |
|------|-----|--------|--------|---------|
| **è„šæœ¬è¯­è¨€** | JavaScript | Python | GUI + Java DSL | Scala |
| **å­¦ä¹ æ›²çº¿** | ğŸŸ¢ ç®€å• | ğŸŸ¢ ç®€å• | ğŸŸ¡ ä¸­ç­‰ | ğŸ”´ å¤æ‚ |
| **åˆ†å¸ƒå¼æµ‹è¯•** | âœ… éœ€è¦é…ç½® | âœ… åŸç”Ÿæ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ |
| **å®æ—¶ç›‘æ§** | âœ… | âœ… UI | âœ… UI | âœ… |
| **æŠ¥å‘Š** | âœ… JSON/HTML | âœ… | âœ… | âœ… HTML |
| **èµ„æºå ç”¨** | ä½ | ä½ | é«˜ | ä½ |
| **CI/CD é›†æˆ** | âœ… | âœ… | âœ… | âœ… |
| **æœ€é€‚ç”¨åœºæ™¯** | API è´Ÿè½½æµ‹è¯• | å¤æ‚ç”¨æˆ·è¡Œä¸º | é€šç”¨ | é«˜å¹¶å‘æ€§èƒ½æµ‹è¯• |
